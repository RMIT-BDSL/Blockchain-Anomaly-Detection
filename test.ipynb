{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a604a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.878332 ± 0.007699\n",
      "AP : 0.667361 ± 0.015456\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the text file\n",
    "file_path = 'results/SAGE/results_TI.csv'  # replace with your actual filename\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "auc_mean = df['AUC'].mean()\n",
    "auc_std = df['AUC'].std()\n",
    "\n",
    "ap_mean = df['AP'].mean()\n",
    "ap_std = df['AP'].std()\n",
    "\n",
    "# Print results\n",
    "print(f\"AUC: {auc_mean:.6f} ± {auc_std:.6f}\")\n",
    "print(f\"AP : {ap_mean:.6f} ± {ap_std:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bf7f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch-scatter\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f5/ab/2a44ecac0f891dd0d765fc59ac8d277c6283a31907626560e72685df2ed6/torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
      "\u001b[33m  DEPRECATION: Building 'torch-scatter' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-scatter'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for torch-scatter (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[47 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.linux-x86_64-cpython-313/torch_scatter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.linux-x86_64-cpython-313/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.linux-x86_64-cpython-313/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-cpython-313/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-cpython-313/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py:480: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.6). Most likely this shouldn't be a problem.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "  \u001b[31m   \u001b[0m /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py:490: UserWarning: There are no g++ version bounds defined for CUDA version 12.2\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-313/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c csrc/cpu/scatter_cpu.cpp -o build/temp.linux-x86_64-cpython-313/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c csrc/scatter.cpp -o build/temp.linux-x86_64-cpython-313/csrc/scatter.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib build/temp.linux-x86_64-cpython-313/csrc/cpu/scatter_cpu.o build/temp.linux-x86_64-cpython-313/csrc/scatter.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-313/torch_scatter/_scatter_cpu.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cuda' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-313/csrc/cuda\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c csrc/cpu/scatter_cpu.cpp -o build/temp.linux-x86_64-cpython-313/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=_scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.\n",
      "  \u001b[31m   \u001b[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m /usr/local/cuda/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c csrc/cuda/scatter_cuda.cu -o build/temp.linux-x86_64-cpython-313/csrc/cuda/scatter_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=_scatter_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++17\n",
      "  \u001b[31m   \u001b[0m gcc: fatal error: cannot execute ‘cc1plus’: execvp: No such file or directory\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m nvcc fatal   : Failed to preprocess host compiler properties.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/local/cuda/bin/nvcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-scatter\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-scatter\n",
      "Failed to build torch-scatter\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (torch-scatter)\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch-sparse\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/42/e2/cddf10a8e32a0b214918943e6173672c8ec11000e69c36dad8e6b141cb60/torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-sparse) (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from scipy->torch-sparse) (2.2.6)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "\u001b[33m  DEPRECATION: Building 'torch-sparse' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-sparse'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[247 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.linux-x86_64-cpython-313/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py:480: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.6). Most likely this shouldn't be a problem.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "  \u001b[31m   \u001b[0m /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py:490: UserWarning: There are no g++ version bounds defined for CUDA version 12.2\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._sample_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/sample_cpu.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cpu/sample_cpu.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [2/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/sample.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/sample.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/sample_cpu.o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/sample.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-313/torch_sparse/_sample_cpu.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._sample_cuda' extension\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/sample_cpu.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cpu/sample_cpu.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [2/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/sample.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/sample.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/sample_cpu.o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/sample.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-313/torch_sparse/_sample_cuda.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._hgt_sample_cpu' extension\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/hgt_sample.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/hgt_sample.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/hgt_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_hgt_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [2/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/hgt_sample_cpu.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cpu/hgt_sample_cpu.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/hgt_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_hgt_sample_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/hgt_sample_cpu.o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/hgt_sample.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-313/torch_sparse/_hgt_sample_cpu.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._hgt_sample_cuda' extension\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/hgt_sample_cpu.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cpu/hgt_sample_cpu.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/hgt_sample_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_hgt_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [2/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/hgt_sample.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/hgt_sample.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/hgt_sample.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_hgt_sample_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/hgt_sample_cpu.o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/hgt_sample.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-313/torch_sparse/_hgt_sample_cuda.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._version_cpu' extension\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/1] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/version.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/version.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/version.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-313/torch_sparse/_version_cpu.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._version_cuda' extension\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/1] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/version.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/version.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_version_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/version.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-313/torch_sparse/_version_cuda.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._diag_cpu' extension\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/diag_cpu.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cpu/diag_cpu.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/diag_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_diag_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [2/2] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/diag.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/diag.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/diag.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_diag_cpu -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/data_hdd_16t/miniconda3/envs/dd-pro/lib -Wl,-rpath-link,/data_hdd_16t/miniconda3/envs/dd-pro/lib -L/data_hdd_16t/miniconda3/envs/dd-pro/lib /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/diag_cpu.o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/diag.o -L/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-313/torch_sparse/_diag_cpu.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._diag_cuda' extension\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cuda\n",
      "  \u001b[31m   \u001b[0m /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.\n",
      "  \u001b[31m   \u001b[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cuda/diag_cuda.o.d -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cuda/diag_cuda.cu -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cuda/diag_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++17\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: \u001b[0m/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cuda/diag_cuda.o\n",
      "  \u001b[31m   \u001b[0m /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cuda/diag_cuda.o.d -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cuda/diag_cuda.cu -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cuda/diag_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 -std=c++17\n",
      "  \u001b[31m   \u001b[0m gcc: fatal error: cannot execute ‘cc1plus’: execvp: No such file or directory\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m nvcc fatal   : Failed to preprocess host compiler properties.\n",
      "  \u001b[31m   \u001b[0m [2/3] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/diag_cpu.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/cpu/diag_cpu.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/cpu/diag_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [3/3] c++ -MMD -MF /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/diag.o.d -pthread -B /data_hdd_16t/miniconda3/envs/dd-pro/share/python_compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -O2 -isystem /data_hdd_16t/miniconda3/envs/dd-pro/include -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/third_party/parallel-hashmap -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include -I/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/data_hdd_16t/miniconda3/envs/dd-pro/include/python3.13 -c -c /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/csrc/diag.cpp -o /tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/build/temp.linux-x86_64-cpython-313/csrc/diag.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1016\"' -DTORCH_EXTENSION_NAME=_diag_cuda -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++17\n",
      "  \u001b[31m   \u001b[0m ninja: build stopped: subcommand failed.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py\"\u001b[0m, line \u001b[35m2506\u001b[0m, in \u001b[35m_run_ninja_build\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msubprocess.run\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mcommand,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<3 lines>...\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mcheck=True,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31menv=env)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/subprocess.py\"\u001b[0m, line \u001b[35m577\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m                              output=stdout, stderr=stderr)\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35msubprocess.CalledProcessError\u001b[0m: \u001b[35mCommand '['ninja', '-v']' returned non-zero exit status 1.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(compile('''\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m# This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<32 lines>...\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31mexec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m''' % ('/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/setup.py',), \"<pip-setuptools-caller>\", \"exec\"))\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<pip-setuptools-caller>\"\u001b[0m, line \u001b[35m35\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/tmp/pip-install-5rbx79hv/torch-sparse_186e539e04d04a1d819ffe9b59db1f94/setup.py\"\u001b[0m, line \u001b[35m147\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msetup\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mname='torch_sparse',\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<23 lines>...\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31minclude_package_data=include_package_data,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/__init__.py\"\u001b[0m, line \u001b[35m117\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return \u001b[31mdistutils.core.setup\u001b[0m\u001b[1;31m(**attrs)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m            \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/core.py\"\u001b[0m, line \u001b[35m186\u001b[0m, in \u001b[35msetup\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/core.py\"\u001b[0m, line \u001b[35m202\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mdist.run_commands\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m983\u001b[0m, in \u001b[35mrun_commands\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m999\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/command/bdist_wheel.py\"\u001b[0m, line \u001b[35m379\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(\"build\")\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/cmd.py\"\u001b[0m, line \u001b[35m339\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.distribution.run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m999\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/command/build.py\"\u001b[0m, line \u001b[35m136\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.run_command\u001b[0m\u001b[1;31m(cmd_name)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/cmd.py\"\u001b[0m, line \u001b[35m339\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.distribution.run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/dist.py\"\u001b[0m, line \u001b[35m999\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31msuper().run_command\u001b[0m\u001b[1;31m(command)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/dist.py\"\u001b[0m, line \u001b[35m1002\u001b[0m, in \u001b[35mrun_command\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mcmd_obj.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/command/build_ext.py\"\u001b[0m, line \u001b[35m99\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m_build_ext.run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m365\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.build_extensions\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py\"\u001b[0m, line \u001b[35m1010\u001b[0m, in \u001b[35mbuild_extensions\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mbuild_ext.build_extensions\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m481\u001b[0m, in \u001b[35mbuild_extensions\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself._build_extensions_serial\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m507\u001b[0m, in \u001b[35m_build_extensions_serial\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mself.build_extension\u001b[0m\u001b[1;31m(ext)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/command/build_ext.py\"\u001b[0m, line \u001b[35m264\u001b[0m, in \u001b[35mbuild_extension\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m_build_ext.build_extension\u001b[0m\u001b[1;31m(self, ext)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/setuptools/_distutils/command/build_ext.py\"\u001b[0m, line \u001b[35m562\u001b[0m, in \u001b[35mbuild_extension\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     objects = self.compiler.compile(\n",
      "  \u001b[31m   \u001b[0m         sources,\n",
      "  \u001b[31m   \u001b[0m     ...<5 lines>...\n",
      "  \u001b[31m   \u001b[0m         depends=ext.depends,\n",
      "  \u001b[31m   \u001b[0m     )\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py\"\u001b[0m, line \u001b[35m815\u001b[0m, in \u001b[35munix_wrap_ninja_compile\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m_write_ninja_file_and_compile_objects\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31msources=sources,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<11 lines>...\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mwith_cuda=with_cuda,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mwith_sycl=with_sycl)\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py\"\u001b[0m, line \u001b[35m2159\u001b[0m, in \u001b[35m_write_ninja_file_and_compile_objects\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m_run_ninja_build\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31mbuild_directory,\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<2 lines>...\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m# that failed to build but there isn't a good way to get it here.\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31merror_prefix='Error compiling objects for extension')\u001b[0m\n",
      "  \u001b[31m   \u001b[0m         \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages/torch/utils/cpp_extension.py\"\u001b[0m, line \u001b[35m2522\u001b[0m, in \u001b[35m_run_ninja_build\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(message) from e\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mRuntimeError\u001b[0m: \u001b[35mError compiling objects for extension\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-sparse\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (torch-sparse)\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch-geometric in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (2.2.6)\n",
      "Requirement already satisfied: scipy in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (1.15.3)\n",
      "Requirement already satisfied: networkx in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (3.5)\n",
      "Requirement already satisfied: scikit-learn in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (1.6.1)\n",
      "Requirement already satisfied: requests in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: plyfile in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (1.1.2)\n",
      "Requirement already satisfied: pandas in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: rdflib in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (7.1.4)\n",
      "Requirement already satisfied: h5py in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (3.14.0)\n",
      "Requirement already satisfied: googledrivedownloader in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from torch-geometric) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from pandas->torch-geometric) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from pandas->torch-geometric) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from pandas->torch-geometric) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->torch-geometric) (1.17.0)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from rdflib->torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from requests->torch-geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from requests->torch-geometric) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from scikit-learn->torch-geometric) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /data_hdd_16t/miniconda3/envs/dd-pro/lib/python3.13/site-packages (from scikit-learn->torch-geometric) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter\n",
    "!pip install torch-sparse\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec547b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd-pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
